{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Word Counter\n",
    "\n",
    "Menghitung kata penting dalam dokumen TXT, DOCX, dan PDF.\n",
    "\n",
    "- Emelsha Viadra (152022056)\n",
    "- Naufal Zaidan (152022168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import docx \n",
    "import fitz  \n",
    "import pandas as pd\n",
    "\n",
    "NRP_1 = \"152022056\"\n",
    "NAMA_1 = \"Emelsha Viadra\"\n",
    "NRP_2 = \"152022168\"\n",
    "NAMA_2 = \"Naufal Zaidan\"\n",
    "STOPWORD_FILE = r\"stopwordbahasa.csv\"\n",
    "directory = \"text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Stopwords Function \n",
    "Fungsi `load_stopwords(filepath)`:\n",
    "- Input: Path file CSV yang berisi daftar stopwords\n",
    "- Proses: Membaca file CSV tanpa header menggunakan pandas\n",
    "- Output: Set dari stopwords untuk pencarian yang lebih efisien\n",
    "- Kegunaan: Memuat kata-kata umum yang akan difilter dari perhitungan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(filepath):\n",
    "    stopwords = pd.read_csv(filepath, header=None)[0].tolist()\n",
    "    return set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Reading Functions \n",
    "\n",
    "read_txt(filepath)\n",
    "- Input: Path file TXT\n",
    "- Proses: Membuka dan membaca file teks dengan encoding UTF-8\n",
    "- Output: String berisi seluruh isi file\n",
    "\n",
    " read_docx(filepath)\n",
    "- Input: Path file DOCX\n",
    "- Proses: Membaca dokumen Word dan menggabungkan semua paragraf\n",
    "- Output: String berisi seluruh teks dari dokumen\n",
    "\n",
    " read_pdf(filepath)\n",
    "- Input: Path file PDF\n",
    "- Proses: Membaca setiap halaman PDF dan menggabungkan teksnya\n",
    "- Output: String berisi seluruh teks dari PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "def read_docx(filepath):\n",
    "    doc = docx.Document(filepath)\n",
    "    return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "def read_pdf(filepath):\n",
    "    doc = fitz.open(filepath)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Text Processing Functions \n",
    "\n",
    " tokenize(text)\n",
    "- Input: String teks\n",
    "- Proses:\n",
    "  1. Mengkonversi teks ke lowercase\n",
    "  2. Menggunakan regex untuk memisahkan kata-kata\n",
    "  3. Pattern `\\b\\w+\\b`: mencari kata yang terdiri dari karakter word (\\w)\n",
    "- Output: List token-token kata\n",
    "\n",
    " filter_tokens(tokens, stopwords)\n",
    "- Input: List token dan set stopwords\n",
    "- Proses: Menyaring token yang tidak ada dalam stopwords\n",
    "- Output: List token yang sudah difilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b[\\w-]+\\b', text)\n",
    "    return tokens\n",
    "\n",
    "def filter_tokens(tokens, stopwords):\n",
    "    return [token for token in tokens if token not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Document Processing Function \n",
    "\n",
    "Fungsi `process_document(filepath, stopwords)`:\n",
    "- Input: Path file dan set stopwords\n",
    "- Proses:\n",
    "  1. Mendeteksi tipe file (.txt, .docx, .pdf)\n",
    "  2. Memanggil fungsi pembaca yang sesuai\n",
    "  3. Melakukan tokenisasi teks\n",
    "  4. Memfilter stopwords\n",
    "  5. Menghitung frekuensi kata dengan Counter\n",
    "- Output: Dictionary berisi frekuensi setiap kata penting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(filepath, stopwords):\n",
    "    if filepath.endswith(\".txt\"):\n",
    "        content = read_txt(filepath)\n",
    "    elif filepath.endswith(\".docx\"):\n",
    "        content = read_docx(filepath)\n",
    "    elif filepath.endswith(\".pdf\"):\n",
    "        content = read_pdf(filepath)\n",
    "    else:\n",
    "        raise ValueError(f\"Format file tidak didukung: {filepath}\")\n",
    "\n",
    "    tokens = tokenize(content)\n",
    "    filtered_tokens = filter_tokens(tokens, stopwords)\n",
    "    word_counts = Counter(filtered_tokens)\n",
    "    print(word_counts)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Main Execution \n",
    "\n",
    "Program utama melakukan:\n",
    "1. Menampilkan identitas mahasiswa\n",
    "2. Memuat stopwords dari file CSV\n",
    "3. Meminta input direktori dari user\n",
    "4. Validasi keberadaan direktori\n",
    "5. Untuk setiap file yang didukung (.txt, .docx, .pdf):\n",
    "   - Membaca dan memproses file\n",
    "   - Menampilkan hasil perhitungan kata\n",
    "   - Menangani error jika terjadi masalah\n",
    "\n",
    "Output menampilkan:\n",
    "- Kata-kata penting yang ditemukan\n",
    "- Frekuensi kemunculan setiap kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRP: 152022056\n",
      "NAMA: Emelsha Viadra\n",
      "NRP: 152022168\n",
      "NAMA: Naufal Zaidan\n",
      "\n",
      "Memproses dokumen di direktori: text\n",
      "\n",
      "Membaca file: Penerapan Algoritma FP-Growth Dalam Analisis Pola Asosiasi pada Penjualan Supermarket.docx\n",
      "Counter({'fp-growth': 17, 'data': 16, 'algoritma': 12, 'pola': 12, 'item': 11, 'frekuen': 10, 'frequent': 8, 'transaksi': 8, 'fp-tree': 8, 'analisis': 7, 'support': 7, 'mining': 6, 'itemset': 6, 'teknologi': 3, 'industri': 3, 'pattern': 3, 'muncul': 3, 'menghasilkan': 3, 'efisien': 3, 'tree': 3, 'pemrosesan': 3, 'penelitian': 3, 'rumus': 3, 'database': 3, 'x': 3, 'batas': 3, 'minimum': 3, 'a': 3, 'penerapan': 2, 'asosiasi': 2, 'menemukan': 2, 'dirancang': 2, 'item-item': 2, 'apriori': 2, 'kandidat': 2, 'membangun': 2, 'struktur': 2, 'bentuk': 2, 'pohon': 2, 'dataset': 2, 'domain': 2, 'retail': 2, 'e-commerce': 2, 'pelanggan': 2, 'meningkatkan': 2, 'aplikasi': 2, 'variasi': 2, 'alat': 2, 'big': 2, 'konsep': 2, 'd': 2, 't': 2, 'ditentukan': 2, 'hitung': 2, 'frekuensi': 2, 'memenuhi': 2, 'urutkan': 2, 'fp': 2, 'penjualan': 1, 'supermarket': 1, 'disusun': 1, 'emelsha': 1, 'viadra': 1, '152022056': 1, 'naufal': 1, 'zaidan': 1, '152022168': 1, 'prodi': 1, 'informatika': 1, 'fakultas': 1, 'institut': 1, 'nasional': 1, 'bandung': 1, '2024': 1, 'growth': 1, 'basis': 1, 'kompleks': 1, 'mengidentifikasi': 1, 'bersamaan': 1, 'market': 1, 'basket': 1, 'analysis': 1, 'berbeda': 1, 'tradisional': 1, 'pemindaian': 1, 'pendekatan': 1, 'merepresentasikan': 1, 'mengeksplorasi': 1, 'mengurangi': 1, 'sumber': 1, 'daya': 1, 'kelebihan': 1, 'utama': 1, 'kemampuannya': 1, 'menangani': 1, 'membuatnya': 1, 'ideal': 1, 'perusahaan': 1, 'pola-pola': 1, 'pembelian': 1, 'berharga': 1, 'gilirannya': 1, 'strategi': 1, 'pemasaran': 1, 'pengelolaan': 1, 'persediaan': 1, 'pengalaman': 1, 'garis': 1, 'sejarah': 1, '2000': 1, 'perkenalan': 1, 'diperkenalkan': 1, 'jiawei': 1, 'han': 1, 'jian': 1, 'pei': 1, 'yiwen': 1, 'yin': 1, 'makalah': 1, 'berjudul': 1, 'patterns': 1, 'without': 1, 'candidate': 1, 'generation': 1, 'mengatasi': 1, 'kelemahan': 1, '2001': 1, 'adopsi': 1, 'diadopsi': 1, 'nyata': 1, 'sektor': 1, '2002-2005': 1, 'pengembangan': 1, 'efisiensinya': 1, 'adaptasi': 1, 'streaming': 1, 'konteks': 1, 'kecepatan': 1, '2006': 1, 'integrasi': 1, 'diintegrasikan': 1, 'platform': 1, 'memudahkan': 1, 'pengguna': 1, 'menerapkan': 1, 'proyek': 1, '2010': 1, 'penggunaan': 1, 'pertumbuhan': 1, 'relevan': 1, 'didukung': 1, 'kemajuan': 1, 'penyimpanan': 1, '2015-sekarang': 1, 'berkelanjutan': 1, 'fokus': 1, 'komunitas': 1, 'inovasi': 1, 'menjelajahi': 1, 'efisiensi': 1, 'penerapannya': 1, 'kesehatan': 1, 'web': 1, 'berfokus': 1, 'penemuan': 1, 'kunci': 1, 'mengukur': 1, 'menghitung': 1, 'total': 1, 'himpunan': 1, 'mengandung': 1, 'dianggap': 1, 'support-nya': 1, 'melebihi': 1, 'ambang': 1, 'min_support': 1, 'pembangunan': 1, 'menyimpan': 1, 'relasinya': 1, 'proses': 1, 'pembangunannya': 1, 'meliputi': 1, 'langkah-langkah': 1, 'kemunculan': 1, 'buang': 1, 'hapus': 1, 'berdasarkan': 1, 'kemunculannya': 1, 'tertinggi': 1, 'terendah': 1, 'bangun': 1, 'tambahkan': 1, 'sesuai': 1, 'urutan': 1, '3': 1, 'ekstraksi': 1, 'dibangun': 1, 'langkah': 1, 'mengekstrak': 1, 'rekursif': 1, 'lakukan': 1, 'subtree': 1, 'terhubung': 1, 'identifikasi': 1, 'dihasilkan': 1, 'mencakup': 1, 'studi': 1, 'menentukan': 1, '2': 1, 'mencari': 1, 'items': 1, 'mengurutkan': 1, 'priority': 1, 'conditional': 1})\n",
      "5 kata terbanyak di Penerapan Algoritma FP-Growth Dalam Analisis Pola Asosiasi pada Penjualan Supermarket.docx:\n",
      "- Kata 'fp-growth' sebanyak 17 kata\n",
      "- Kata 'data' sebanyak 16 kata\n",
      "- Kata 'algoritma' sebanyak 12 kata\n",
      "- Kata 'pola' sebanyak 12 kata\n",
      "- Kata 'item' sebanyak 11 kata\n",
      "\n",
      "Membaca file: Penerapan Metode K-Nearest Neighbors (K-NN) untuk Klasifikasi Risiko .pdf\n",
      "Counter({'data': 66, 'jarak': 29, 'k-nn': 21, 'sampel': 18, 'algoritma': 17, '3': 17, 'uji': 17, 'no': 16, '2': 15, 'hasil': 14, '4': 12, '5': 12, 'klasifikasi': 11, 'diabetes': 11, 'tetangga': 11, 'terdekat': 11, '22': 11, '21': 10, '26': 10, 'k': 9, 'memiliki': 9, '25': 9, '14': 9, '24': 9, '6': 8, '88': 8, '7': 8, '27': 8, '23': 8, 'metode': 7, 'dataset': 7, '8': 7, '11': 7, '17': 7, 'k-nearest': 6, 'neighbors': 6, 'distance': 6, 'titik': 6, 'fitur': 6, 'diklasifikasikan': 6, 'pengenalan': 6, 'berisiko': 6, '28': 6, '31': 6, '10': 6, '13': 6, '62': 6, 'euclidean': 5, 'bidang': 5, 'tabel': 5, 'diabet': 5, '33': 5, '30': 5, '34': 5, '18': 5, '19': 5, '20': 5, 'pengujian': 5, '67': 5, 'kelas': 4, 'pola': 4, 'salah': 4, 'dasar': 4, 'pembelajaran': 4, 'mesin': 4, '43': 4, '53': 4, '9': 4, '12': 4, '15': 4, '16': 4, '82': 4, '93': 4, '68': 4, 'kesehatan': 3, 'menentukan': 3, 'nilai': 3, 'mengklasifikasikan': 3, 'utama': 3, 'dihitung': 3, 'berdasarkan': 3, 'mayoritas': 3, 'perkembangan': 3, 'penggunaan': 3, 'populer': 3, 'aplikasi': 3, 'x': 3, 'y': 3, '103': 3, '32': 3, '36': 3, '70': 3, '58': 3, '42': 3, '64': 3, 'euclidian': 3, 'urutan': 3, '80': 3, '02': 3, '29': 3, '87': 3, 'ketiga': 3, 'penerapan': 2, 'risiko': 2, 'teknologi': 2, 'industri': 2, 'learning': 2, 'kedekatan': 2, 'model': 2, 'overfitting': 2, 'proses': 2, 'metrik': 2, 'lurus': 2, 'ruang': 2, 'kali': 2, 'relevan': 2, 'positif': 2, 'kesederhanaannya': 2, 'rumit': 2, 'lambat': 2, 'menghitung': 2, 'sejarah': 2, 'statistik': 2, 'teori': 2, '1951': 2, 'evelyn': 2, 'fix': 2, 'joseph': 2, 'hodges': 2, 'makalah': 2, 'berjudul': 2, 'penelitian': 2, '1967': 2, 'cover': 2, 'hart': 2, 'mengembangkan': 2, 'pengklasifikasian': 2, 'sederhana': 2, 'komputasi': 2, 'mengukur': 2, 'gula': 2, 'darah': 2, 'insulin': 2, 'bmi': 2, 'usia': 2, '89': 2, '168': 2, '59': 2, '51': 2, '45': 2, '115': 2, '125': 2, '41': 2, '140': 2, '145': 2, '110': 2, '54': 2, '192': 2, '37': 2, '56': 2, '101': 2, '100': 2, '71': 2, '63': 2, '199': 2, '90': 2, '195': 2, '55': 2, '40': 2, '35': 2, '250': 2, '255': 2, '196': 2, '49': 2, '153': 2, 'disusun': 1, 'emelsha': 1, 'viadra': 1, '152022056': 1, 'naufal': 1, 'zaidan': 1, '152022168': 1, 'prodi': 1, 'informatika': 1, 'fakultas': 1, 'institut': 1, 'nasional': 1, 'bandung': 1, '2024': 1, 'supervised': 1, 'regresi': 1, 'memanfaatkan': 1, 'kemiripan': 1, 'prediksinya': 1, 'penerapannya': 1, 'menetapkan': 1, 'parameter': 1, 'dipertimbangkan': 1, 'pemilihan': 1, 'peka': 1, 'kehilangan': 1, 'sensitivitas': 1, 'lokal': 1, 'melibatkan': 1, 'perhitungan': 1, 'manhattan': 1, 'minkowski': 1, 'diukur': 1, 'dimensi': 1, 'berbeda-beda': 1, 'normalisasi': 1, 'memilih': 1, 'terkecil': 1, 'tahap': 1, 'kelebihan': 1, 'pelatihan': 1, 'kelemahannya': 1, 'ukuran': 1, 'berakar': 1, 'kecerdasan': 1, 'buatan': 1, 'analisis': 1, 'konsep': 1, 'dikenal': 1, 'abad': 1, 'ke-20': 1, 'signifikan': 1, 'pertengahan': 1, '1900-an': 1, 'poin': 1, 'penemuan': 1, 'diperkenalkan': 1, 'discriminatory': 1, 'analysis': 1, 'nonparametric': 1, 'discrimination': 1, 'consistency': 1, 'properties': 1, 'universitas': 1, 'california': 1, 'berkeley': 1, 'fokus': 1, 'pengembangan': 1, 'non-parametrik': 1, 'membahas': 1, 'kumpulan': 1, 'label': 1, 'buku': 1, 'the': 1, 'theory': 1, 'of': 1, 'pattern': 1, 'recognition': 1, 'thomas': 1, 'm': 1, 'peter': 1, 'e': 1, 'efektif': 1, 'asumsi': 1, 'distribusi': 1, 'menginspirasi': 1, 'ilmuwan': 1, 'berbasis': 1, '1970-an': 1, 'diadopsi': 1, 'pendekatan': 1, 'kuat': 1, 'utamanya': 1, 'bioinformatika': 1, 'wajah': 1, 'tulisan': 1, 'tangan': 1, '1980-1990-an': 1, 'era': 1, 'munculnya': 1, 'cepat': 1, 'terjangkau': 1, 'meluas': 1, 'kompleks': 1, 'komputer': 1, 'vision': 1, 'suara': 1, 'diagnosis': 1, 'medis': 1, '2000-an': 1, 'kebangkitan': 1, 'berkembangnya': 1, 'machine': 1, 'diajarkan': 1, 'pemodelan': 1, 'keuangan': 1, 'perdagangan': 1, 'elektronik': 1, 'dianggap': 1, 'mudah': 1, 'dipahami': 1, 'diterapkan': 1, 'keterbatasan': 1, 'rentan': 1, 'performa': 1, 'eksplorasi': 1, 'rumus': 1, 'x1': 1, 'x2': 1, 'xn': 1, 'y1': 1, 'y2': 1, 'yn': 1, 'penjelasan': 1, 'jaraknya': 1, 'xi': 1, 'yi': 1, 'ke-i': 1, 'n': 1, 'contoh': 1, 'penyakit': 1, 'dialami': 1, 'masyarakat': 1, 'deteksi': 1, 'mencegah': 1, 'komplikasi': 1, 'studi': 1, 'terkena': 1, 'faktor': 1, '94': 1, '137': 1, '78': 1, '197': 1, '543': 1, '189': 1, '846': 1, '166': 1, '175': 1, '118': 1, '230': 1, '83': 1, '96': 1, '126': 1, '235': 1, '39': 1, '143': 1, '146': 1, '97': 1, '57': 1, '158': 1, '245': 1, '111': 1, '207': 1, '180': 1, '171': 1, '240': 1, '176': 1, '300': 1, '150': 1, '342': 1, '38': 1, 'penyelesaian': 1, 'ambil': 1, 'acuan': 1, '187': 1, '304': 1, '155': 1, '495': 1, '46': 1, '232': 1, '242': 1, '50': 1, '239': 1, '542': 1, '131': 1, '99': 1, '236': 1, '220': 1, '164': 1, '188': 1, '74': 1, '269': 1, '124': 1, '234': 1, '61': 1, '238': 1, '282': 1, '298': 1, '249': 1, '114': 1, '491': 1, '08': 1, '788': 1, '69': 1, '135': 1, '174': 1, '52': 1, '76': 1, '77': 1, '128': 1, '86': 1, '148': 1, '252': 1, '66': 1, '284': 1, '48': 1, '407': 1, '327': 1, '414': 1, '352': 1, '320': 1, '268': 1, '415': 1, '401': 1, '262': 1, '349': 1, '381': 1, '360': 1, '385': 1, '47': 1, '446': 1, '307': 1, '291': 1, '426': 1, '417': 1, '462': 1, '477': 1, '428': 1, '04': 1, '373': 1, 'ringkasan': 1})\n",
      "5 kata terbanyak di Penerapan Metode K-Nearest Neighbors (K-NN) untuk Klasifikasi Risiko .pdf:\n",
      "- Kata 'data' sebanyak 66 kata\n",
      "- Kata 'jarak' sebanyak 29 kata\n",
      "- Kata 'k-nn' sebanyak 21 kata\n",
      "- Kata 'sampel' sebanyak 18 kata\n",
      "- Kata 'algoritma' sebanyak 17 kata\n",
      "\n",
      "Membaca file: text.txt\n",
      "Counter({'teknologi': 2, 'data': 2, 'berkembang': 1, 'pesat': 1, 'bidang': 1, 'kesehatan': 1, 'pendidikan': 1, 'transportasi': 1, 'inovasi': 1, 'kecerdasan': 1, 'buatan': 1, 'ai': 1, 'pekerjaan': 1, 'efisien': 1, 'analisis': 1, 'pengenalan': 1, 'pola': 1, 'sisi': 1, 'tantangan': 1, 'keamanan': 1, 'etika': 1, 'penggunaannya': 1, 'perhatian': 1, 'utama': 1, 'masyarakat': 1, 'memahami': 1, 'dampak': 1, 'kehidupan': 1, 'sehari-hari': 1, 'beradaptasi': 1, 'perubahan': 1})\n",
      "5 kata terbanyak di text.txt:\n",
      "- Kata 'teknologi' sebanyak 2 kata\n",
      "- Kata 'data' sebanyak 2 kata\n",
      "- Kata 'berkembang' sebanyak 1 kata\n",
      "- Kata 'pesat' sebanyak 1 kata\n",
      "- Kata 'bidang' sebanyak 1 kata\n"
     ]
    }
   ],
   "source": [
    "print(f\"NRP: {NRP_1}\")\n",
    "print(f\"NAMA: {NAMA_1}\")\n",
    "print(f\"NRP: {NRP_2}\")\n",
    "print(f\"NAMA: {NAMA_2}\\n\")\n",
    "\n",
    "stopwords = load_stopwords(STOPWORD_FILE)\n",
    "\n",
    "print(\"Memproses dokumen di direktori:\", directory)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"Direktori {directory} tidak ditemukan.\")\n",
    "else:\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "        if filepath.endswith((\".txt\", \".docx\", \".pdf\")):\n",
    "            print(f\"\\nMembaca file: {filename}\")\n",
    "            try:\n",
    "                word_counts = process_document(filepath, stopwords)\n",
    "                print(f\"5 kata terbanyak di {filename}:\")\n",
    "                top_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                for word, count in top_words:\n",
    "                    print(f\"- Kata '{word}' sebanyak {count} kata\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error memproses file {filename}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
